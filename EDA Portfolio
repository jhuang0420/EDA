{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11012113,"sourceType":"datasetVersion","datasetId":6856230}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports \nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport seaborn as sns\nsns.set(style='whitegrid')\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport math\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset Overview \ndf = pd.read_csv('/kaggle/input/healthcare-survey/health_dataset.csv');\ndf = df.drop(columns=['ADM_RNO1']) # ID col, not useful\nprint(df.dtypes)\nprint(df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for Missing Data \nprint('------ Percent Missing Data > 0 -----')\nmissing = 100 * df.isnull().sum() / df.shape[0]\nprint(missing[missing > 0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Handle Missing Data \n# Drop rows in this case since very few missing\ndf = df.dropna()\nprint(df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check Unique Values for Columns\npd.Series({col:df[col].unique() for col in df})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Correlation of Columns\ndef plt_corr_heatmap(df):\n    plt.figure(figsize=(14,13))\n    sns.heatmap(df.corr(), annot=False, cmap='coolwarm', linewidths=0.2)\n    plt.title(\"Correlation Heatmap\")\n    plt.show()\n\nplt_corr_heatmap(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop cols with strong correlation\ndef drop_strong_corr(df, threshold=0.95):\n    corr = df.corr().abs()\n    upper_triangle = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n    df = df.drop(columns=to_drop)\n    return df\n\ndf = drop_strong_corr(df)\nprint(df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt_corr_heatmap(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pie plot for value distribution of columns with less than [threshold] unique values\ndef plot_pie(df, threshold=15, cols_per_row=5):\n    pie_cols = [col for col in df if len(df[col].unique()) < threshold]\n    num_plots = len(pie_cols)\n \n    rows = math.ceil(num_plots / cols_per_row)\n    fig, axes = plt.subplots(rows, cols_per_row, figsize=(cols_per_row * 5, rows * 5))\n    axes = axes.flatten() \n\n    for i, col in enumerate(pie_cols):\n        df[col].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90, ax=axes[i])\n        axes[i].set_title(f'Distribution of {col}')\n        axes[i].set_ylabel('')\n\n    # Hide unused subplots if any\n    for j in range(i + 1, len(axes)): fig.delaxes(axes[j])\n\n    plt.tight_layout()\n    plt.show()\n\n# plot_pie(df)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Histogram plots for columns with less than [threshold] unique values\ndef plot_hist(df, threshold=15, cols_per_row=5):\n    hist_cols = [col for col in df if len(df[col].unique()) < threshold]\n    num_plots = len(hist_cols)\n    \n    rows = math.ceil(num_plots / cols_per_row)\n    fig, axes = plt.subplots(rows, cols_per_row, figsize=(cols_per_row * 5, rows * 5))\n    axes = axes.flatten() \n\n    for i, col in enumerate(hist_cols):\n        df[col].value_counts().plot(kind='bar', ax=axes[i])\n        axes[i].set_title(f'Distribution of {col}')\n        axes[i].set_xlabel(col)\n        axes[i].set_ylabel('Count')\n\n    for j in range(i + 1, len(axes)): fig.delaxes(axes[j])\n\n    plt.tight_layout()\n    plt.show()\n\nplot_hist(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop rows where data is less than [threshold]% of the data\ndef drop_rare_rows(df, threshold=0.000001):\n    df_filtered = df.copy() \n    for col in df_filtered.columns:\n        counts = df_filtered[col].value_counts(normalize=True)  # Get normalized counts\n        rare_values = counts[counts < threshold].index  # Find rare values\n        df_filtered = df_filtered[~df_filtered[col].isin(rare_values)]  # Drop rows with rare values\n    return df_filtered  \n\n# df_filtered = drop_rare_rows(df)\n# print(df_filtered.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def kde_plot(df, cols_per_row=5):\n    num_cols = df.select_dtypes(include=['number']).columns  # Select only numerical columns\n    if len(num_cols) == 0: return\n\n    rows = math.ceil(len(num_cols) / cols_per_row)\n    fig, axes = plt.subplots(rows, cols_per_row, figsize=(cols_per_row * 5, rows * 5))\n    axes = axes.flatten()\n    \n    for i, col in enumerate(num_cols):\n        sns.kdeplot(df[col], fill=True, alpha=0.4, ax=axes[i])  # Specify axis\n        axes[i].set_title(f'KDE for {col}')\n        axes[i].set_xlabel(col)\n        axes[i].set_ylabel('Density')\n\n    for j in range(i + 1, len(axes)): fig.delaxes(axes[j])\n    plt.tight_layout()\n    plt.show()\n\n\nkde_plot(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print unique values and counts for each col\ndef print_unique_count(df, threshold=20):\n    for col in df.columns:\n        unique_values = df[col].nunique()  \n        print(f\"{col:20s} {unique_values} unique with bounds [{df[col].min()}, {df[col].max()}]\") \n\n        if unique_values < threshold: print(df[col].value_counts(), \"\\n\")\n\nprint_unique_count(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correction to Life_satisfaction values\ndf['Life_satisfaction'] = df['Life_satisfaction'].replace({99:10, 98:10, 97:10})\nprint(df['Life_satisfaction'].value_counts())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the distribution of cols with unique values > threshold\ndef get_distribution(df, threshold=20, q1=0.25, q3=0.75):\n    cols = [col for col in df.columns if df[col].nunique() >= threshold]\n    \n    for col in cols:\n        q1_val, q3_val = df[col].quantile(q1), df[col].quantile(q3)\n        print(f\"-----{col}------\")\n        print(f\"Min: {df[col].min():0.2f}, Max: {df[col].max():0.2f}\")\n        print(f\"Mean: {df[col].mean():0.2f}\")\n        print(f\"Median: {df[col].median():0.2f}\")\n        print(f\"{q1*100:1.0f}th quartile: {q1_val:0.2f}\")\n        print(f\"{q3*100:1.0f}th quartile: {q3_val:0.2f}\")\n        print(f\"Percentage < q1: {(df[col] < q1_val).sum()/df[col].size:0.3f}\")\n        print(f\"Percentage > q3: {(df[col] > q3_val).sum()/df[col].size:0.3f}\")\n\nget_distribution(df,q1=0.1,q3=0.9)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}